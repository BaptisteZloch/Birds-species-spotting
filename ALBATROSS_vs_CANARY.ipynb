{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ALBATROSS vs CANARY.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMx5KunECDGS33+sFdVjNSN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BaptisteZloch/Birds-species-spotting/blob/main/ALBATROSS_vs_CANARY.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zhFCHqBJ9jf"
      },
      "source": [
        "# Kaggle API installing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YP8k-gFU574q"
      },
      "source": [
        "!pip install -q kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gW_-wm06Bhu"
      },
      "source": [
        "from google.colab import files\r\n",
        "files.upload() #upload your JSON token Kaggle API"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ev-2CWCL6PTo"
      },
      "source": [
        "! mkdir ~/.kaggle\r\n",
        "! cp kaggle.json ~/.kaggle/\r\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9j4yySVKG0s"
      },
      "source": [
        "# Dataset\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYT6wyG16kuJ"
      },
      "source": [
        "!kaggle datasets download -d gpiosenka/100-bird-species #files loading"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lq8dAO6e7Ql2"
      },
      "source": [
        "!unzip 100-bird-species.zip #files extracting"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kF56XLKev9VJ"
      },
      "source": [
        "!cp -R /content/valid/ALBATROSS/ /content/Valid_2/\r\n",
        "!cp -R /content/valid/CANARY/ /content/Valid_2/\r\n",
        "!cp -R /content/train/ALBATROSS/ /content/Train_2/\r\n",
        "!cp -R /content/train/CANARY/ /content/Train_2/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Im3R3YvnJj1K"
      },
      "source": [
        "## Image preprocessing\r\n",
        "\r\n",
        "We will label the data based on their folders and we will also use data augmentation to make our model better."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TcgmAq4JjCS"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "\r\n",
        "# All images will be augmented\r\n",
        "train_datagen = ImageDataGenerator(\r\n",
        "                  rotation_range=40,\r\n",
        "                  width_shift_range=0.2,\r\n",
        "                  height_shift_range=0.2,\r\n",
        "                  shear_range=0.2,\r\n",
        "                  zoom_range=0.2,\r\n",
        "                  horizontal_flip=True,\r\n",
        "                  fill_mode='nearest',\r\n",
        "                  rescale=1/255)\r\n",
        "\r\n",
        "# Flow training images in batches of 128 using train_datagen generator\r\n",
        "train_generator = train_datagen.flow_from_directory(\r\n",
        "        '/content/Train_2/',  # This is the source directory for training images\r\n",
        "        target_size=(128, 128),\r\n",
        "        batch_size=128,\r\n",
        "        class_mode='binary',\r\n",
        "        color_mode='rgb')\r\n",
        "\r\n",
        "validation_datagen = ImageDataGenerator(rescale=1/255)\r\n",
        "\r\n",
        "validation_generator = validation_datagen.flow_from_directory(\r\n",
        "        '/content/Valid_2/',\r\n",
        "        target_size=(128, 128),\r\n",
        "        class_mode='binary',\r\n",
        "        color_mode='rgb')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2xGb95umkz-"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cIYVO_dJTsJ"
      },
      "source": [
        "## Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_Osa5vO8qW_"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "\r\n",
        "model = tf.keras.models.Sequential([\r\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(128, 128, 3)),\r\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\r\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\r\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\r\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\r\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\r\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\r\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\r\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\r\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\r\n",
        "    tf.keras.layers.Flatten(),\r\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\r\n",
        "    tf.keras.layers.Dense(300, activation='relu'),\r\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\r\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSAqatVK9Ghn"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),\r\n",
        "             loss='binary_crossentropy',\r\n",
        "             metrics=['accuracy'])\r\n",
        "\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sXsO9ZLmtQq"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNPWHhrnD5wU"
      },
      "source": [
        "history = model.fit(\r\n",
        "     train_generator,\r\n",
        "      steps_per_epoch= 293 // 128,\r\n",
        "      epochs=15,\r\n",
        "      verbose=1,\r\n",
        "      validation_data=validation_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2mnXKQFMjmN"
      },
      "source": [
        "model.save(\"mymodel.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldJ6dzLkmTFP"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mObHWFXOmxc-"
      },
      "source": [
        "## Evalute the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnNkuLCJgo5X"
      },
      "source": [
        "import numpy as np\r\n",
        "from keras.preprocessing import image\r\n",
        "\r\n",
        "species = ['CANARY','ALBATROSS']\r\n",
        "\r\n",
        "for specie in species:\r\n",
        "  for i in range(1,6):\r\n",
        "    img = image.load_img('/content/test/'+specie+'/'+ str(i) +'.jpg', target_size=(128, 128))\r\n",
        "    x = image.img_to_array(img)\r\n",
        "    x = np.expand_dims(x, axis=0)\r\n",
        "    image_tensor = np.vstack([x])\r\n",
        "    classes = model.predict(image_tensor)\r\n",
        "    if classes[0]>0.5:\r\n",
        "      print(\"Predicted  : CANARY      Real : \"+specie)\r\n",
        "    else:\r\n",
        "      print(\"Predicted  : ALBATROSS      Real : \"+specie)\r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}